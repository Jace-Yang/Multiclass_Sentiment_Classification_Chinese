{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jace-Yang/Multiclass_Sentiment_Classification_Chinese/blob/main/Deploying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "525XFs9ZiaQF"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR77jTblj3o8"
      },
      "source": [
        "### Set up for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF1fYe6WLheW",
        "outputId": "15bb59fb-d96a-4dea-8f91-f6e846bb3090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# For runing notebook in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "root_of_repository = '/content/drive/MyDrive/ADL/Project/'\n",
        "os.chdir(root_of_repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3o65vJ6ika_",
        "outputId": "12810c6e-6c35-4e65-c5f6-3fc32945f0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 6.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XplycqVMkDlk"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TkDtjNgliaQI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import copy\n",
        "import time\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model_utils import test"
      ],
      "metadata": {
        "id": "wGKqnwRrGQlM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SentimentModel(nn.Module):\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes, model_name, pretrain_path, hidden_size):\n",
        "        '''\n",
        "        pretrain_path: local or hugging-face path, e.g '/roberta-wwm-ext pretrain/'\n",
        "        '''\n",
        "        super(Model, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(pretrain_path, return_dict=False)\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True  # Allow all parameters to be updated\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)   # A layer to calculate logits of 6 ouput classes from 768 (hidden size of BERT)\n",
        "            # Note: We are going to use Cross-EntropyLoss with a softmax “embedded”.\n",
        "    def forward(self, x, token_type_ids, attention_mask):\n",
        "        context = x  # Input sentence\n",
        "        segments = token_type_ids\n",
        "        mask = attention_mask  # Only mask the padding part\n",
        "        _, pooled = self.bert(context, token_type_ids=segments, attention_mask=mask)\n",
        "        logits = self.fc(pooled) # probability of 6 classes\n",
        "        return logits"
      ],
      "metadata": {
        "id": "4us6vgypBaSe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev8M5OS8iaQJ"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7bRQKKZciaQJ"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 128\n",
        "BATCH_SIZE = 8\n",
        "LABEL_DICT = {'fear':0, 'neutral':1, 'sad':2, 'surprise':3, 'angry':4, 'happy':5} # Mapping label code and meaning\n",
        "TOKENIZER = BertTokenizer.from_pretrained(\"chinese_wwm_ext_pytorch\") # Hugging face BertTokenizer to load pretrain model\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm-ext\")\n",
        "#model = BertModel.from_pretrained(\"hfl/chinese-bert-wwm-ext\")\n",
        "\n",
        "\n",
        "DEVELOPMENT_SET_PATH = 'data/usual_train.txt'\n",
        "TEST_SET_PATH = 'data/usual_test_labeled.txt'\n",
        "\n",
        "def convert_text_to_token(tokenizer, sentence, seq_length):\n",
        "    \"\"\"Tokenize sentence\n",
        "\n",
        "    Args:\n",
        "        tokenizer (PreTrainedTokenizer): a pretrained tokenizer with special token set to \n",
        "            {'unk_token': '[UNK]', 'sep_token': '[SEP]', \n",
        "             'pad_token': '[PAD]', 'cls_token': '[CLS]', \n",
        "             'mask_token': '[MASK]'}\n",
        "        sentence (str): \n",
        "        seq_length (int): length of maximum input sentence accepted\n",
        "    \n",
        "    Returns: tuple(word_ids, segments, attention_masks)\n",
        "        word_ids (list): tokenized sentence\n",
        "        segments (list): label segmentation of original sentence and padding\n",
        "        attention_masks (list): label whether the word is masked\n",
        "    \"\"\" \n",
        "    tokens = tokenizer.tokenize(sentence) # Tokenize the sentence\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] # Add [CLS] before token and [SEP] after token\n",
        "    word_ids = tokenizer.convert_tokens_to_ids(tokens) # Generate list of word id\n",
        "    segments = [0] * len(word_ids) # Label whether it is segmented\n",
        "    attention_masks = [1] * len(word_ids) # Label whether the word is masked\n",
        "    # Chop or pad the sentence into a single length - seq_length\n",
        "    if len(word_ids) < seq_length: # Padding\n",
        "        length_to_pad = seq_length - len(word_ids)\n",
        "        word_ids += [0] * length_to_pad # [0] is the index of word \"PAD\" in the vocabulary table\n",
        "        segments += [1] * length_to_pad # [1] denotes that this part of words are PAD\n",
        "        attention_masks += [0] * length_to_pad # Change attention mask of PAD part as [0]\n",
        "    else: # Chopping\n",
        "        word_ids = word_ids[:seq_length]\n",
        "        segments = segments[:seq_length]\n",
        "        attention_masks = attention_masks[:seq_length]\n",
        "    assert len(word_ids) == len(segments) == len(attention_masks)\n",
        "    return word_ids, segments, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jg3IwJdt3U40"
      },
      "outputs": [],
      "source": [
        "# All pretrain models in chinese\n",
        "MODELS_PATHS_UNITS = {\n",
        "    'BERT': ('bert-base-chinese', 768),\n",
        "    'BERT-wwm': ('hfl/chinese-bert-wwm-ext', 768),\n",
        "    'RoBERTa': ('uer/chinese_roberta_L-12_H-768', 768),\n",
        "    'RoBERTa-wwm': ('hfl/chinese-roberta-wwm-ext', 768),\n",
        "    'RoBERTa-wwm-large': ('hfl/chinese-roberta-wwm-ext-large', 1024),\n",
        "    'Re-trained RoBERTa-wwm': ('hfl/rbt3', 768),\n",
        "    'Re-trained RoBERTa-wwm-large': ('hfl/rbtl3', 1024),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BVWX4qf0Z1E8"
      },
      "outputs": [],
      "source": [
        "def pred(word, model):\n",
        "    cur_ids, cur_type, cur_mask = convert_text_to_token(TOKENIZER, word, seq_length=SEQ_LENGTH)\n",
        "    cur_ids, cur_type, cur_mask = torch.LongTensor(np.array([cur_ids])).to(DEVICE), torch.LongTensor(np.array([cur_type])).to(DEVICE), torch.LongTensor(np.array([cur_mask])).to(DEVICE) # 数据构造成tensor形式\n",
        "    with torch.no_grad():\n",
        "        y_ = model(cur_ids, token_type_ids=cur_type, attention_mask=cur_mask)\n",
        "        pred = y_.max(-1, keepdim=True)[1]  # 取最大值\n",
        "        # cur_pre = LABEL_DICT[int(pred[0][0].cuda().data.cpu().numpy())] # 预测的情绪\n",
        "        cur_pre = LABEL_NAME_DICT[int(pred[0][0].data.cpu().numpy())] # 预测的情绪\n",
        "        print(cur_pre)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TESTING = True\n",
        "BEST_MODEL_FOLDER = 'result/model/'  # Path to save best model\n",
        "TRAINING_LOGS_FOLDER = 'result/training/'  # Path to save training logs\n",
        "TESTING_LOGS_FOLDER = 'result/testing/'  # Path to save testing logs\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LABEL_NAME_DICT = {0:'fear', 1:'neutral', 2:'sad', 3:'surprise', 4:'angry', 5:'happy'}\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxYYj_nIcztq",
        "outputId": "21e45d4d-b858-4f12-a340-6dcbb3d6be10"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each pretrain model\n",
        "for model_name in tqdm(MODELS_PATHS_UNITS.keys()):\n",
        "\n",
        "    model_path = f'{BEST_MODEL_FOLDER}best_{model_name}.pth' if not TESTING else f'{BEST_MODEL_FOLDER}best_testing_{model_name}.pth'\n",
        "    # Initialize a model\n",
        "    sentiment_classifier = Model(num_classes=6,\n",
        "                                 model_name=model_name,\n",
        "                                 pretrain_path=MODELS_PATHS_UNITS[model_name][0],\n",
        "                                 hidden_size=MODELS_PATHS_UNITS[model_name][1]).to(DEVICE)\n",
        "\n",
        "    # Load model parameters\n",
        "    sentiment_classifier.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "\n",
        "    # Evaluate on testset\n",
        "    # pred('草泥马好可爱', sentiment_classifier)\n",
        "    pred('今天我赚了一亿块钱', sentiment_classifier)\n",
        "    pred('我一个月只能赚三千块钱', sentiment_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "d1f132612b2446f8a4fb617018e94c2c",
            "f41846b2d7fd4fe9b77da2fb5f51aafb",
            "d2dc9c0c5fe8434ca79a35052f5b28e3",
            "4b9cda8f47e8482ea30d4443a1bc5c3d",
            "b56264930d4e49b28813868ed0b47109",
            "c424b28138d0436697b97ab45e2d3a98",
            "07a5d3e5006546c18b0353f1113a5826",
            "e5dd73e0583240d49abcbdbd1a3c62fc",
            "6844e54966794fdd8b01a6609c690d30",
            "f2d539a78857495da0ec67a7e4f0fa69",
            "1f9c042e60dc4efb88fdea39de8784b1"
          ]
        },
        "id": "2azlUHXRcgsz",
        "outputId": "3f7a8869-9b37-4aaa-ede1-b913305e0fa0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1f132612b2446f8a4fb617018e94c2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy\n",
            "sad\n",
            "happy\n",
            "sad\n",
            "happy\n",
            "sad\n",
            "happy\n",
            "sad\n",
            "neutral\n",
            "sad\n",
            "sad\n",
            "sad\n",
            "sad\n",
            "sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71e6HSQiiaQP",
        "outputId": "9683509e-a07d-4376-c44d-04a439ec572e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n"
          ]
        }
      ],
      "source": [
        "pred('草！我爱死你了！！！！！！！！！！！', MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTHhUGcmiaQP",
        "outputId": "00d299c7-a83b-48cc-a940-1d809f3412c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy\n"
          ]
        }
      ],
      "source": [
        "pred('世界上五大最可爱动物:草泥马第二', MODEL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.15 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b006d4e027c423e1c5ba60767ca029aac904db329267b6e9db0756472a8771f5"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1f132612b2446f8a4fb617018e94c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f41846b2d7fd4fe9b77da2fb5f51aafb",
              "IPY_MODEL_d2dc9c0c5fe8434ca79a35052f5b28e3",
              "IPY_MODEL_4b9cda8f47e8482ea30d4443a1bc5c3d"
            ],
            "layout": "IPY_MODEL_b56264930d4e49b28813868ed0b47109"
          }
        },
        "f41846b2d7fd4fe9b77da2fb5f51aafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c424b28138d0436697b97ab45e2d3a98",
            "placeholder": "​",
            "style": "IPY_MODEL_07a5d3e5006546c18b0353f1113a5826",
            "value": "100%"
          }
        },
        "d2dc9c0c5fe8434ca79a35052f5b28e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5dd73e0583240d49abcbdbd1a3c62fc",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6844e54966794fdd8b01a6609c690d30",
            "value": 7
          }
        },
        "4b9cda8f47e8482ea30d4443a1bc5c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d539a78857495da0ec67a7e4f0fa69",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9c042e60dc4efb88fdea39de8784b1",
            "value": " 7/7 [01:00&lt;00:00,  8.30s/it]"
          }
        },
        "b56264930d4e49b28813868ed0b47109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c424b28138d0436697b97ab45e2d3a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a5d3e5006546c18b0353f1113a5826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5dd73e0583240d49abcbdbd1a3c62fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6844e54966794fdd8b01a6609c690d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2d539a78857495da0ec67a7e4f0fa69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9c042e60dc4efb88fdea39de8784b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}